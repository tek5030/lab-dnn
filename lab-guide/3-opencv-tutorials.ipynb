{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: OpenCV Tutorials\n",
    "\n",
    "In this part, we will familiarize ourselves with OpenCV's tools for deep learning by looking at the [dnn/samples] and [tutorials] for the dnn module.\n",
    "\n",
    "We will take [samples/dnn/edge_detection.py] as a starting point, as this is a bite-sized task that highlights some useful concepts of the dnn module of OpenCV.\n",
    "Read more about the \"_Holistically-Nested Edge Detection_\" [here][model]!\n",
    "\n",
    "---\n",
    "\n",
    "## Downloading models\n",
    "\n",
    "First, we will download a model that has been trained with the [Caffe] framework.\n",
    "OpenCV can also load networks represented in several other formats.\n",
    "Take a look at the documentation for [cv.dnn.readNet], which we will employ later.\n",
    "\n",
    "Just for fun, we will utilize the `download_models.py` script from the [dnn/samples] directory.\n",
    "You can read more about the script in the [README][samples/README], where you see that its primary use case is to download models specified in [dnn/samples/models.yml] by just referring to the model's name.\n",
    "\n",
    "Unfortunately, our edge detection net is not present in models.yml, so we locate the correct URLs from the [model] repository.\n",
    "\n",
    "Run the following cells to get started!\n",
    "\n",
    "[model]: https://github.com/s9xie/hed\n",
    "[dnn/samples]: https://github.com/opencv/opencv/tree/4.x/samples/dnn\n",
    "[tutorials]: https://docs.opencv.org/4.x/d2/d58/tutorial_table_of_content_dnn.html\n",
    "[samples/dnn/edge_detection.py]: https://github.com/opencv/opencv/blob/4.x/samples/dnn/edge_detection.py\n",
    "[Caffe]: http://caffe.berkeleyvision.org/\n",
    "[cv.dnn.readNet]: https://docs.opencv.org/4.x/d6/d0f/group__dnn.html#ga4823489a689bf4edfae7447eb807b067\n",
    "[samples/README]: https://github.com/opencv/opencv/blob/4.x/samples/dnn/README.md\n",
    "[dnn/samples/models.yml]: https://github.com/opencv/opencv/blob/4.x/samples/dnn/models.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-16T01:18:59.066187313Z",
     "start_time": "2024-02-16T01:18:58.865462692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Working on deploy.prototxt\n",
      "  Getting file deploy.prototxt\n",
      "  expected SHA1: 4f01b87a9cda4912f6751d4ea7acc8866a26b077\n",
      "  there is already a file with the same name\n",
      "  actual SHA1:4f01b87a9cda4912f6751d4ea7acc8866a26b077\n",
      "  hash match - file already exists, skipping\n",
      "  Working on hed_pretrained_bsds.caffemodel\n",
      "  Getting file hed_pretrained_bsds.caffemodel\n",
      "  expected SHA1: 2c5d7842f25f880eec62fc610b500c5cf2aa351d\n",
      "  there is already a file with the same name\n",
      "  actual SHA1:2c5d7842f25f880eec62fc610b500c5cf2aa351d\n",
      "  hash match - file already exists, skipping\n"
     ]
    }
   ],
   "source": [
    "# Obtain the 'download_models.py'\n",
    "samples_url = \"https://raw.githubusercontent.com/opencv/opencv/4.x/samples/dnn\"\n",
    "!wget -qO download_models.py \"{samples_url}/download_models.py\"\n",
    "\n",
    "from download_models import downloadFile\n",
    "\n",
    "# Create dicts that we can feed right into 'downloadFile'\n",
    "caffemodel = {\n",
    "    \"url\": \"https://vcl.ucsd.edu/hed/hed_pretrained_bsds.caffemodel\",\n",
    "    \"filename\": \"hed_pretrained_bsds.caffemodel\",\n",
    "    \"sha\": \"2c5d7842f25f880eec62fc610b500c5cf2aa351d\"\n",
    "}\n",
    "\n",
    "prototxt = {\n",
    "    \"url\": \"https://raw.githubusercontent.com/s9xie/hed/master/examples/hed/deploy.prototxt\",\n",
    "    \"filename\": \"deploy.prototxt\",\n",
    "    \"sha\": \"4f01b87a9cda4912f6751d4ea7acc8866a26b077\"\n",
    "}\n",
    "\n",
    "# Download the files.\n",
    "# Downloading the model might take quite a while, be patient.\n",
    "config = downloadFile(**prototxt, save_dir=\".\")\n",
    "model = downloadFile(**caffemodel, save_dir=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying the network\n",
    "\n",
    "If you inspect the `deploy.prototxt` file that describes the network, you may see that there are several layers of type `Crop`.\n",
    "\"Crop layers\" receive two input blobs and crop the first one to match the spatial dimensions of the second one.\n",
    "\n",
    "Our model was trained with a crop layer that crops from the center of the image, while the cv.dnn.CropLayer (and also more recent Caffe crop layer) crops from the top-left corner.\n",
    "\n",
    "In order to prevent shifted results caused by this discrepancy in cropping logic, we're going to replace OpenCV's Crop layer (that makes top-left cropping) by a centric one.\n",
    "\n",
    "You can read more about custom layers in the [OpenCV tutorial: Custom deep learning layers support](https://docs.opencv.org/4.9.0/dc/db1/tutorial_dnn_custom_layers.html).\n",
    "There are several other use cases for custom layers, and playing around with it will enhance your understandig of what layers do in a net.\n",
    "\n",
    "### Challenge: Define the crop area\n",
    "\n",
    "Look at the image below, and try to work out the crop area, expressed in terms of coordinates `xstart, ystart` and `xend, yend`.\n",
    "Remember that the values you should use are in terms of the input_shape.\n",
    " \n",
    "![Cropping the inputs](./getMemoryShapes.png)\n",
    "\n",
    "Modify the cell below, and run it when you have a solution for the cropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-16T01:19:01.495002634Z",
     "start_time": "2024-02-16T01:19:01.487863450Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "class CropLayer(object):\n",
    "    def __init__(self, params, blobs):\n",
    "        self.xstart = 0\n",
    "        self.xend = 0\n",
    "        self.ystart = 0\n",
    "        self.yend = 0\n",
    "\n",
    "    # Our layer receives two inputs. We need to crop the first input blob\n",
    "    # to match a shape of the second one (keeping batch size and number of channels)\n",
    "    # Returns layer's output shapes depending on input shapes. \n",
    "    def getMemoryShapes(self, inputs):\n",
    "        input_shape  = inputs[0]\n",
    "        batch_size, num_channels  = input_shape[0], input_shape[1]\n",
    "        input_height, input_width = input_shape[2], input_shape[3]\n",
    "\n",
    "        target_shape = inputs[1]\n",
    "        target_height, target_width = target_shape[2], target_shape[3]\n",
    "\n",
    "        # TODO: Define the crop area\n",
    "        self.ystart = 0\n",
    "        self.xstart = 0\n",
    "        self.yend = 0\n",
    "        self.xend = 0\n",
    "\n",
    "        return [[batch_size, num_channels, target_height, target_width]]\n",
    "\n",
    "    # Implementation of layer's logic. Compute outputs for given inputs.\n",
    "    def forward(self, inputs):\n",
    "        return [inputs[0][:, :, self.ystart:self.yend, self.xstart:self.xend]]\n",
    "\n",
    "# cv.dnn_registerLayer('Crop', CropLayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Running the net\n",
    "\n",
    "Now we are ready to try the edge detection model, so we load it with [cv.dnn.readNet].\n",
    "Take a look at the documentation. What arguments does `readNet` take, and what kind of object does it return?\n",
    "Examine the code below and look for usages of `net`. Several concepts from this week's lectures should be familiar.\n",
    "You should also check out the documentation for [cv.dnn.blobFromImage]. What is a \"blob\"?\n",
    "\n",
    "We continue with our main processing loop. Make sure to get the camera index right!\n",
    "\n",
    "[cv.dnn.readNet]: https://docs.opencv.org/4.x/d6/d0f/group__dnn.html#ga4823489a689bf4edfae7447eb807b067\n",
    "[cv.dnn.blobFromImage]: https://docs.opencv.org/4.x/d6/d0f/group__dnn.html#ga29f34df9376379a603acd8df581ac8d7\n",
    "\n",
    "Run the cell below in order to test our edge detector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-16T01:19:56.690412673Z",
     "start_time": "2024-02-16T01:19:54.095145105Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = cv.dnn.readNet(model=model, config=config)\n",
    "net.setPreferableBackend(cv.dnn.DNN_BACKEND_DEFAULT)\n",
    "net.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)\n",
    "window_name = 'Holistically-Nested Edge Detection'\n",
    "cv.namedWindow('Input', cv.WINDOW_NORMAL)\n",
    "cv.namedWindow(window_name, cv.WINDOW_NORMAL)\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "while cv.waitKey(1) < 0:\n",
    "    hasFrame, frame = cap.read()\n",
    "    if not hasFrame:\n",
    "        cv.waitKey()\n",
    "        break\n",
    "\n",
    "    cv.imshow('Input', frame)\n",
    "\n",
    "    inp = cv.dnn.blobFromImage(frame, scalefactor=1.0, size=(500, 500),\n",
    "                                mean=(104.00698793, 116.66876762, 122.67891434),\n",
    "                                swapRB=False, crop=False)\n",
    "    net.setInput(inp)\n",
    "\n",
    "    out = net.forward()\n",
    "    out = out[0, 0]\n",
    "    out = cv.resize(out, (frame.shape[1], frame.shape[0]))\n",
    "    cv.imshow(window_name, out)\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Revisited\n",
    "\n",
    "Oh no! We forgot to register our new layer! In the output video, you should notice how the cropping fails,\n",
    "and we get a padded border along the top and left edges of the output image.\n",
    "\n",
    "This does also mean that we haven't tested _your_ cropping yet!\n",
    "\n",
    "Try again after removing the comment before this line in the previous cell.\n",
    "\n",
    "```py\n",
    "# cv.dnn_registerLayer('Crop', CropLayer)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-16T01:20:53.309240769Z",
     "start_time": "2024-02-16T01:20:53.267094990Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You may have to repeat this in order to re-run the program,\n",
    "# or you may have to restart the ipykernel/notebook `\"¯\\_(ツ)_/¯ \"`\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Next step\n",
    "Great work!\n",
    "\n",
    "You can now proceed to [the final step](4-further-work.md).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
